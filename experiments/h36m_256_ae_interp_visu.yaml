GPUS : '0' # indices of gpus available on servers. CPU mode is not available, only GPU!
PRINT_FREQ : 50 # frequency of printing statistics or any other stuff
OUTPUT_DIR : 'output/ae_full/visu' # path from the root folder to the save folder
SAVE_EVERY_EPOCH : False

VISU :
  ae:
    OUTPUT_PATH : 'output/ae_full/ae_latent32_fc256_layer4_100ep_H36M_full'
    WEIGHT_PATH : '/best_copy.pth'
    TRAIN_LOSS_PATH : '/metrics/ae_loss_train.pth'
    VALID_LOSS_PATH : '/metrics/ae_loss_valid.pth'

  mpjpe:
    OUTPUT_PATH : 'output/ae_full/ae_latent32_fc256_layer4_100ep_H36M_full'
    WEIGHT_PATH : '/best_copy.pth'
    TRAIN_LOSS_PATH : '/metrics/mpjpe_loss_train.pth'
    VALID_LOSS_PATH : '/metrics/mpjpe_loss_valid.pth'

MODELS : # NN-models to create
  ae: # network name that will be used in the experiment
    DIR : 'acai' # file in 'lib/models/<DIR>.py' where the model lies
    ARCH : 'AE' # name of the NN-model class to initialize
    PARAMS : # all attributes in the __init__ of the model class
      latent_dim : 32
      img_shape :
        - 17
        - 3
      layers_dim : 256
      nb_layers : 4 # for encoder and decoder each, counting input and output layers
      dropout : 0

LOSSES : # loss functions to create 
  ae_loss : 
    DIR : 'joints_loss' # file in 'lib/losses/<DIR>.py' where the loss class lies
    NAME : 'JointsLoss' # name of the NN-loss class to initialize
    PARAMS :
      criterion : 'L2'

  mpjpe_loss :
    DIR : 'joints_loss'
    NAME : 'MPJPE'

OPTIM : # optimizers to use
  ae : # must coincide with the name of the network!
    NAME : 'Adam' # torch.optim.<NAME>
    PARAMS :
      lr : 0.001

SCHED : # schedulers to use 
  ae : # must coincide with the name of the network!
    NAME : 'ReduceLROnPlateau' # torch.optim.lr_scheduler.<NAME>
    PARAMS :
      mode : 'min'
      factor : 0.5
      verbose : True
      min_lr : 0.000001
      patience : 10


DATASETS : # datasets to initialize
  train : # name of the dataset that will be used in the experiment
    DIR : 'h36m_3d' # file in 'lib/datasets/<DIR>.py' where the dataset class lies
    NAME : 'H36M' # name of the dataset class to initialize
    PARAMS :
      subjects : ['S1', 'S5', 'S6','S7', 'S8']
      shuffle : True
      seed : 1234
      skip_frames : 1
      augmentations : {
          'rotate' : {
              'max_angle' : 30
          },
          'flip' : True,
      }

  valid : 
    DIR : 'h36m_3d'
    NAME : 'H36M'
    PARAMS :
      subjects : ['S9']
      shuffle : True
      seed : 1234
      skip_frames : 1
      
DATALOAD : # dataloaders to iterate over dataset
  train : # must coincide with the name of dataset
    NUM_ITERATIONS_PER_EPOCH : 1 # len(dataloader) == NUM_ITERATIONS, not len(dataloader(dataset)) as usual
    PARAMS :
      shuffle : True
      batch_size : 32
      num_workers : 5
  valid :
    NUM_ITERATIONS_PER_EPOCH : 1 # len(dataloader) == NUM_ITERATIONS, not len(dataloader(dataset)) as usual
    PARAMS :
      shuffle : False
      batch_size : 1000
      num_workers : 5

TRAINING : # experiment specifications
  END_EPOCH : 1 
  RESUME :
    LOAD_MODELS_ONLY : True # if True load weights as initialization, "fine-tuning" mode
    CKPT : '/home/facades/projects/stud_proj_pose_interp/output/ae_full/ae_latent32_fc256_layer4_100ep_H36M_full/best.pth' # path where the pretrained model lies


PROCEDURE : 'proc_ae_interp_visu' # file 'lib/procedures/procedures/<PROCEDURE>.py' where train() and valid() are specified

EXP_NAME : 'ae_latent32_fc256_layer4_100ep_H36M_full_interp_visu'